{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDs:\n",
    "Insert yours IDs to the cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID #1:\n",
    "\n",
    "ID #2:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the following instructions carefully:\n",
    "\n",
    "1. This jupyter notebook contains all the step by step instructions needed for this exercise.\n",
    "1. You are free to add cells.\n",
    "1. Write your functions and your answers in this jupyter notebook only.\n",
    "1. Answers to theoretical questions should be written in **markdown cells (with $\\LaTeX$ support)**.\n",
    "1. Submit this jupyter notebook only using your ID as a filename. Not to use ZIP or RAR. For example, your Moodle submission file name should look like this (two id numbers): `123456789_987654321.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 - Defective products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a manufacturing pipeline products are 3% defective. We are interested in examining a defective product to see what goes wrong on the belt. We need to ask the facility manager to send us a set of independent samples for examination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.A\n",
    "\n",
    "How many independent samples should we ask for in order to have a 85% probability of having at least one defective product in the batch sent? You should write a function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binomial distribution with p=0.03. If X is the number of defective products out of n, we are looking for P=85% for at least 1  defective product:\n",
    "\n",
    "$0.85 = 1-P(X=0) \\rightarrow P(X=0) = 0.15$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(range(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.8532360949640706, 63}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sb\n",
    "\n",
    "def binom_PDF(n,k,p):\n",
    "    \"helper function: binom PDF\"\n",
    "    return math.comb(n, k)*(p**k)*(1-p)**(n-k)\n",
    "\n",
    "def binom_find_n(target_k,p,target_P,max_n):\n",
    "    \"\"\"recieves the target P and calcualtes n iteratively\n",
    "    the value of n is the number of trials to have probablility >= target_p\"\"\"\n",
    "    for n in range(1,max_n):\n",
    "        P = 0\n",
    "        for k in range(0,target_k+1):\n",
    "            P += binom_PDF(n,k,p)\n",
    "        P = 1 - P\n",
    "        if (P >= target_P):\n",
    "            return {n,P}\n",
    "    return \"error\"\n",
    "\n",
    "binom_find_n(0,0.03,0.85,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we will require at least 63 samples and the probability of at least 1 defective prodcut is $1-0.146 = 0.854$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.B\n",
    "Answer this part again with the following changes: products are 4% defective and we want a 95% probability of at least one defective product in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.9512391525501656, 74}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binom_find_n(0,0.04,0.95,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we will require at least 74 samples to have a $1-0.048 = 0.952$ probabillity of a defective product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.C \n",
    "\n",
    "Consider the following cases and calculate how many independent samples are required: \n",
    "\n",
    "1. Products are 10% defective and we want a 90% probability of at least 5 defective products in the batch.\n",
    "1. Products are 30% defective and we want a 90% probability of at least 15 defective products in the batch.\n",
    "\n",
    "Explain the difference between the two results. You should use mathematical reasoning based on the properties of distributions you saw in class and visualizations in your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $P(X >=5) = 1-P(X=0)-P(X=1)-P(X=2)-P(X=3)-P(X=4)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.9006056767326882, 78}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binom_find_n(4,0.1,0.9,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we will require at least 78 products for 90% probability.\n",
    "\n",
    "2. Similarly, $P(X >= 5) = 1 - P(X=0)- P(X=1) - ... - P(X=14)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.902570602815726, 64}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binom_find_n(14,0.3,0.9,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nimuk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 - Rent distributions in Randomistan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The state of Randomistan conducted a survey to study the distribution of rent paid in two neighboring towns, Stochastic Heights and Random Grove, to be denoted SH and RG.<br> \n",
    "\n",
    "Here are some findings of the survey:\n",
    "* The population of SH and RG is 16,000 and 22,000 respectively. <br>\n",
    "* The mean rent in SH and RG is 6300RCU and 4200RCU respectively.\n",
    "* The median rent is 4600RCU in both towns.\n",
    "* The IQR of the rent is smaller in SH than in RG.\n",
    "\n",
    "All data generated in this question needs to be consistent with these findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.A\n",
    "Draw histograms that describe 2 different scenarii of possible distributions of rent in the two towns.\u000b",
    "Your histograms should:<br>\n",
    "* Use bins of 100RCU each.\n",
    "* Have at least 10 non zero bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6300+1700+100*(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10:100\n",
    "15:50\n",
    "5:50\n",
    "20:100\n",
    "\n",
    "mean=15\n",
    "iqr=10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SH = {\n",
    "    # rent:amount\n",
    "    6300+1700+100*(1) :800,\n",
    "    6300+1700+100*(2) :800,\n",
    "    6300+1700+100*(3) :800,\n",
    "    6300+1700+100*(4) :800,\n",
    "    6300+1700+100*(-1):800,\n",
    "    6300+1700+100*(-2):800,\n",
    "    6300+1700+100*(-3):800,\n",
    "    6300+1700+100*(-4):800,\n",
    "    6300+1700+100*(5) :800,\n",
    "    6300+1700+100*(-5):798,\n",
    "    6300+1700+100*(-5) - (7500-4200):1,\n",
    "    6300+1700+100*(-5) + (7500-4200):1,\n",
    "\n",
    "    6300-1700:8000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = []\n",
    "for v,a in SH.items():\n",
    "    array += [v]*a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(arr) #.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_IQR(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RG = {\n",
    "    # rent:amount\n",
    "    4200+500:22000,\n",
    "    4200-500:22000,\n",
    "    4200:22000,\n",
    "    4200+1700:7998,\n",
    "    4200+1700+1:1,\n",
    "    4200+1700-1:1,\n",
    "}\n",
    "SH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[-200,-100,100,200]*(P//4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import pandas as pd\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SH_population = 16_000\n",
    "SH_mean = 6300\n",
    "SH_median = 4600\n",
    "\n",
    "RG_population = 22_000\n",
    "RG_mean = 4200\n",
    "RG_median = 4600\n",
    "\n",
    "def get_IQR(dist):\n",
    "    return np.quantile(dist,0.75) - np.quantile(dist,0.25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we get a distribution that meats all survey conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# population\n",
    "SH_rents = np.array([0]*SH_population)\n",
    "RG_rents = np.array([0]*RG_population)\n",
    "# mean\n",
    "SH_rents = SH_rents + SH_mean\n",
    "RG_rents = RG_rents + RG_mean\n",
    "#median (so that half the population is below the median)\n",
    "SH_rents[:len(SH_rents)//2] = SH_median\n",
    "SH_rents[len(SH_rents)//2:] = SH_median + (SH_mean - SH_median)*2\n",
    "\n",
    "RG_rents[:len(RG_rents)//2] = RG_median\n",
    "RG_rents[len(RG_rents)//2:] = RG_median + (RG_mean - RG_median)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice1 = {\n",
    "    1000:1000,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(SH_rents).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(RG_rents).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IQR for RG should be bigger \n",
    "RG_rents[:len(RG_rents)//2] += 3000\n",
    "RG_rents[-len(RG_rents)//2:] -= 3000\n",
    "pd.Series(RG_rents).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.random.norm(),bins=range(0,10000+100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the median strict \n",
    "SH_rents[:len(SH_rents)//2] = SH_median\n",
    "SH_rents[len(SH_rents)//2:] = SH_median + (SH_mean - SH_median)*2\n",
    "\n",
    "RG_rents[:len(RG_rents)//2] = RG_median\n",
    "RG_rents[len(RG_rents)//2:] = RG_median + (RG_mean - RG_median)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_IQR(RG_rents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_IQR(SH_rents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SH_rents.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RG_rents.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(SH_rents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RG_rents = np.array([460*i for i in range(10)]*1100 + [8600 - 460*i for i in range(10)]*1100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SH_rents.mean(),get_IQR(SH_rents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RG_rents.mean(),get_IQR(RG_rents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(SH_rents),np.median(RG_rents,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "460*9 + (8600 - 460*9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.B\n",
    "Draw a histogram of a third scenario with the same properties. <br>\n",
    "In addition, in this scenario the rent in SH should have a higher variance than the rent in RG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(-.01,.01,10000).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The survey also examined the per household income (PHI) in these two places.<br>\n",
    "\n",
    "It found that:<br>\n",
    "* The mean of PHI in SH is 12500 and in RG is 8500.\n",
    "* The median is 12000 in SH and 8000 in RG.\n",
    "* The covariance of the rent and the PHI was observed to be as in the formula below with $\\alpha=97\\%$ and $\\alpha=89\\%$ in SH and in RG respectively.<br><br>\n",
    "$$Cov(rent, PHI) = \\alpha * \\sqrt{Var(rent)} * \\sqrt{Var(PHI)}$$\n",
    "\n",
    "#### 2.C\n",
    "Produce rent and PHI data for the two cities, that is consistent with these findings. The covariances in your data can deviate by up to 1% from the numbers given $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1=np.array(range(100)) \n",
    "d2=np.array([1]*100) + np.linspace(-0.1,0.1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1.std()**2*(101/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cov(d1,np.r_[d2[:77],d2[-23:][::1]])/((d1.std()**2*(101/100))*(d2.std()**2*(101/100)))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cov(d1,d2/d2.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(d1*d2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.D\n",
    "Produce two heatmaps that describe these two bivariate joint distributions. Make sure you carefully consider the selected binning resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn \n",
    "seaborn.heatmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 - Multinomial Distributions\n",
    "\n",
    "1. Let $X \\sim Multinomial(n,\\vec{p})$ be a multinomial random variable where $n=20$ and $\\vec{p} = (0.2,  0.1,  0.1,  0.1,  0.2,  0.3)$. Note that X is a vector of counts.\n",
    "\n",
    "\n",
    "2. Let $Y = X_2 + X_3 + X_4$ be a random variable.\n",
    "\n",
    "\n",
    "3. Create $k=100$ experiments where $X$ is sampled using Python. Calculate the empirical centralized third moment of $Y$ based on your $k$ experiments.\n",
    "\n",
    "\n",
    "4. Compare your result to the calculation in class for the centralized third moment of the **binomial** distribution and explain your observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y is a random variable based on X which is a multinomial random variable with $n = 20$. \n",
    "So to generate each Y value, we will run $n = 20$ repetitions with 6 possible outcomes, each with a probability taken from the vector $p$. The Y value is the total count of $ X = 2, X = 3$ and $X = 4$ values.\n",
    "\n",
    "This experiment will be preormed $k = 100$ times and the results will be stored in a vector Y[100]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed()\n",
    "k = 100\n",
    "Y = np.zeros((k))\n",
    "for kk in range(0,k):\n",
    "    Y[kk] = np.bincount(np.random.choice(range(6),p=[0.2,  0.1,  0.1,  0.1,  0.2,  0.3],size=(20,)))[[2,3,4]].sum()\n",
    "#Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can compute the empirical central 3rd moment using the formula $E((X-\\mu(X))^k)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9624327918362903"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = Y.mean(axis=0)\n",
    "centralized_third_moment = ((Y - mu)**3).mean()\n",
    "centralized_third_moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to look at Y would be as a binomial distribution where there are 20 experiments. If the result is $X = 2, X = 3$ or $X = 4$ the experiment is sucessful. Therefore the probability of sucess is $P^* = 0.1 + 0.1 + 0.2 = 0.4$.\n",
    "\n",
    "Plugging in the results to the formula for $\\gamma_3$ we recieve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9599999999999997"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 20\n",
    "p = 0.4\n",
    "gamma_3 = n*p*(1-p)*(1-2*p)\n",
    "gamma_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the result is relatively close to the observed value of the third moment. By increasing the number of experiments to 100,000, a closer result is achieved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9882738766859981"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 100000\n",
    "Y = np.zeros((k))\n",
    "for kk in range(0,k):\n",
    "    Y[kk] = np.bincount(np.random.choice(range(6),p=[0.2,  0.1,  0.1,  0.1,  0.2,  0.3],size=(20,)))[[2,3,4]].sum()\n",
    "mu = Y.mean(axis=0)\n",
    "centralized_third_moment = ((Y - mu)**3).mean()\n",
    "centralized_third_moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 - Covariance and independence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the variance of the sum X +Y + Z of three random variables in terms of the variances of X, Y and Z and the covariances between each pair of random variables? What happens if X,Y,Z are pairwise independent? If X,Y,Z are pairwise independent, are they necessarily collectively independent? Prove your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By definition of variance, $Var(X+Y+Z) = E[(X+Y+Z)^2] - E[X+Y+Z]^2$.\n",
    "\n",
    "Expanding the first term:\n",
    "\n",
    "$(X+Y+Z)^2 = (X+Y+Z)(X+Y+Z) = X^2+XY+YZ+YX+Y^2+YZ+ZX+ZY+Z^2 = X^2+Y^2+Z^2+2XY+2XZ+2YZ$\n",
    "\n",
    "And using linearity of expectation we can write:\n",
    "\n",
    "$E[(X+Y+Z)^2] = E[X^2+Y^2+Z^2+2XY+2XZ+2YZ] = E[X^2]+E[Y^2]+E[Z^2]+2E[XY]+2E[XZ]+2E[YZ]$\n",
    "\n",
    "Let's deal with the second term. Again, using linearity of expectation:\n",
    "\n",
    "$E[X+Y+Z]^2 = (E[X] + E[Y] + E[Z])^2 = E[X]^2 + E[Y]^2 + E[Z]^2 + 2E[X]E[Y]+2E[X]E[Z]+2E[Y]E[Z]$\n",
    "\n",
    "And combining the two terms to yield:\n",
    "\n",
    "$\\underbrace{E[X^2] - E[X]^2}_{Var[X]} + \\underbrace{E[Y^2] - E[Y]^2}_{Var[Y]} + \\underbrace{E[Z^2] -  E[Z]^2}_{Var[Z]} + 2(\\underbrace{E[XY]-E[X]E[Y]}_{Cov(X,Y)} + \\underbrace{E[XZ]E[X]E[Z]}_{Cov(X,Z)} + \\underbrace{E[YZ]E[Y]E[Z]}_{Cov(Y,Z)}$\n",
    "\n",
    "Using the definition of covariance: $Cov(x,y) = E[xy]-E[x]E[y]$. So overall:\n",
    "\n",
    "$Var(X+Y+Z) = Var(X) + Var(Y) + Var(Z) + 2(Cov(X,Y) + Cov(X,Z) + Cov(Y,Z))$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 - Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.A\n",
    "Write a program, `Q = NFoldConv(P , n)`, that takes as input:\n",
    "* A distribution, P, of a random variable that takes finitely many integer values\n",
    "* An integer n\n",
    "\n",
    "and produces the distribution, Q, of the sum of n independent repeats of random variables, each of which has the distribution P."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "def conv(P1,P2):\n",
    "    P_res = {} \n",
    "    for v1,p1 in P1.items():\n",
    "        for v2,p2 in P2.items():\n",
    "            P_res[v1+v2] = P_res.get(v1+v2,0) + p1*p2\n",
    "    return P_res\n",
    "\n",
    "def NFoldConv(P, n):\n",
    "    return functools.reduce(conv,[P]*n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.B\n",
    "Compute the distribution of the sum of the results of rolling a fair octahedron 17 times.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/2/27/Octahedron.jpg\" width=\"200\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_res = NFoldConv({i:1/8 for i in range(8)},17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.Series(p_res).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6 - Counting Similar Strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a probaility space $(\\Omega, P)$:\n",
    "* $\\Omega = \\{0,1\\}^n$.\n",
    "* $P$ is induced by independantly a p-coin ($p \\in [0,1]$) n times.\n",
    "\n",
    "For $\\omega \\in \\Omega$ let $W(\\omega) =$ number of 1s in $\\omega$.\n",
    "\n",
    "For $\\omega \\in \\Omega$ let the random variable $C$ be define by:\n",
    "$$C_{p, n}(\\omega) = |\\{\\zeta : W(\\zeta)=W(\\omega)\\}|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.A\n",
    "Plot the distribution of $W$. What is the name of this distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W is a binom distribution ('sum of n bernouli trials')\n",
    "plt.hist(stats.binom(50,0.1).rvs(1000),bins=range(50));\n",
    "plt.title(\"W=binom(50,0.1) example plot\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.B\n",
    "State the formula for comuting $E(C)$.\n",
    "\n",
    "Compute $E(C)$ for $p=0.1, 0.5, 0.8$ and $n=10, 20, 50, 100$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for each value the binom can get the C will get the binom coef with binom_coef*p probability\n",
    "$E(C)=\\sum_{k=0}^{n}{\\binom{n}{k}P_W(\\omega=k)} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=0.1\n",
    "n=10\n",
    "sum([stats.binom(n,p).pmf(k)*math.comb(n,k) for k in range(n+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_EC(n,p):\n",
    "    return np.array([stats.binom(n,p).pmf(k)*math.comb(n,k) for k in range(n+1)]).sum()\n",
    "EC_res=[]\n",
    "for n in [10,20,50,100]:\n",
    "    for p in [0.1,0.5,0.8]:\n",
    "        EC_res.append((n,p,get_EC(n,p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(EC_res,columns=[\"n\",\"p\",\"E(C)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.C \n",
    "Plot the histograms of the values of $C$ for 1000 samples drawn from the space $(\\Omega, P)$ for each combination of $p$ and $n$ from the previous section. Add text to each histogram with the empirical average of $C$ and the computed value of $E(C)$ (from the previous section). In every histogram indicate the values of $n$ and $p$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_sample=1000\n",
    "for n in [10,20,50,100]:\n",
    "    n_map={k:math.comb(n,k) for k in range(n+1)}\n",
    "    for p in [0.1,0.5,0.8]:\n",
    "        values = stats.binom.rvs(n,p,size=N_sample)\n",
    "        values = pd.Series(values).map(n_map)\n",
    "        values = values.values\n",
    "        C_hist = {value:amount for amount,value in zip(*np.histogram(values)) if amount>0}\n",
    "        plt.figure()\n",
    "        pd.Series(C_hist).plot(style='*')\n",
    "        plt.grid()\n",
    "        plt.title(f\"n={n},p={p},mean={values.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.D\n",
    "Use a scatter plot to compare the empirical and the computed values from the previous section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_sample=1000\n",
    "for n in [10,20,50,100]:\n",
    "    n_map={k:math.comb(n,k) for k in range(n+1)}\n",
    "    for p in [0.1,0.5,0.8]:\n",
    "        values = stats.binom.rvs(n,p,size=N_sample)\n",
    "        values = pd.Series(values).map(n_map)\n",
    "        values = values.values\n",
    "        C_hist = {value:amount for amount,value in zip(*np.histogram(values)) if amount>0}\n",
    "        C_hist_expected = {k*math.comb(n,k):math.comb(n,k) for k in range(n+1)}\n",
    "        plt.figure()\n",
    "        pd.Series(C_hist).plot(style='*')\n",
    "        pd.Series(C_hist_expected).plot(style='*')\n",
    "        plt.grid()\n",
    "        plt.title(f\"n={n},p={p},mean={values.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
